## Live Demo

DSGVO Scan Beispiel:
https://dsgvo-scanner-web.vercel.app/report/welt.de

# DSGVO Scanner

Ein Micro-SaaS MVP, das eine Website-URL entgegennimmt, die Seite per Playwright lÃ¤dt und technische DSGVO-relevante Merkmale erkennt: externe Tracker, Fonts, Cookies, Impressum und DatenschutzerklÃ¤rung.

**Kein Login. Kein Sales. Einfach URL eingeben â†’ Ergebnis sehen.**

---

## Features

- Ampel-Anzeige (ğŸ”´ / ğŸŸ¡ / ğŸŸ¢) basierend auf erkannten Trackern
- Erkennt: Google Fonts, Google Analytics / GTM, Facebook Pixel, Tracking-Cookies (`_ga`, `_gid`, `_fbp`)
- PrÃ¼ft Impressum und DatenschutzerklÃ¤rung (Link-Text-Suche)
- Listet alle externen Domains und gesetzten Cookies auf
- Konkrete Fix-Hinweise pro erkanntem Problem
- SSRF-Schutz: Private IPs, DNS-Rebind-Check, Port-Allowlist, Credential-Block
- Rate Limiting: 10 Scans / 10 Minuten / IP + 10s Cooldown
- Idempotency: gleiche URL + IP innerhalb von 2 Minuten â†’ bestehenden Scan zurÃ¼ckgeben

---

## Architektur

```
Browser
  â”‚
  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Next.js 14  (apps/web, Port 3000)      â”‚
â”‚                                          â”‚
â”‚  GET  /scan          URL-Eingabe-Form   â”‚
â”‚  GET  /scan/[id]     Ergebnis + Polling â”‚
â”‚  POST /api/scan      Scan anlegen       â”‚
â”‚  GET  /api/scan/[id] Status abrufen     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ POST /run { scanId }
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Worker (apps/worker, Port 3001)        â”‚
â”‚                                          â”‚
â”‚  Fastify + Playwright Chromium          â”‚
â”‚  â†’ lÃ¤dt URL, sammelt Requests/Cookies   â”‚
â”‚  â†’ schreibt Ergebnis in Supabase        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ reads / writes
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Supabase Postgres                       â”‚
â”‚  table: scans                            â”‚
â”‚  (id, url, status, result, error_msg)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Web â†’ API Route â†’ Worker (fire-and-forget) â†’ Supabase
Browser pollt `/api/scan/[id]` alle 2 Sekunden bis `status = done | error`

---

## Quickstart

### Voraussetzungen

- [Node.js 20+](https://nodejs.org/)
- [pnpm 9+](https://pnpm.io/installation) (`npm install -g pnpm`)
- Ein [Supabase](https://supabase.com)-Konto (kostenloser Free-Tier reicht)

### 1. Repository klonen & Dependencies installieren

```bash
git clone <repo-url>
cd dsgvo-scanner

pnpm install
pnpm rebuild esbuild unrs-resolver   # Build-Scripts genehmigen (einmalig)
```

### 2. Playwright Chromium installieren

```bash
pnpm --filter worker exec playwright install chromium
```

> LÃ¤dt ~300 MB Chrome-Binary herunter. Einmalig nÃ¶tig.

### 3. Supabase einrichten

Siehe [Supabase Setup](#supabase-setup) weiter unten.

### 4. ENV-Dateien anlegen

```bash
cp apps/web/.env.example   apps/web/.env.local
cp apps/worker/.env.example apps/worker/.env
```

Beide Dateien mit den Werten aus dem Supabase-Dashboard befÃ¼llen (siehe [ENV-Variablen](#env-variablen)).

### 5. Starten

**Option A â€” zwei separate Terminals (empfohlen fÃ¼r Logs):**

```bash
# Terminal 1
pnpm dev:worker

# Terminal 2
pnpm dev:web
```

**Option B â€” parallel in einem Terminal:**

```bash
pnpm dev
```

> Worker lÃ¤uft auf http://localhost:3001
> Web lÃ¤uft auf http://localhost:3000

### 6. Fertig

Ã–ffne http://localhost:3000 â†’ gibt zur `/scan`-Seite weiter â†’ URL eingeben â†’ Scan starten.

---

## Supabase Setup

### Projekt erstellen

1. Auf [supabase.com](https://supabase.com) einloggen
2. **New project** â†’ Name vergeben, Region wÃ¤hlen, Passwort setzen
3. Warten bis das Projekt bereit ist (~1 Minute)

### Migrationen ausfÃ¼hren

Im Supabase-Dashboard: **SQL Editor** â†’ **New query**

**Migration 001** â€“ `scans`-Tabelle anlegen:

```sql
-- Inhalt von: supabase/migrations/001_create_scans.sql
create table if not exists public.scans (
  id            uuid        primary key default gen_random_uuid(),
  created_at    timestamptz not null    default now(),
  url           text        not null,
  status        text        not null    check (status in ('queued', 'running', 'done', 'error')),
  result        jsonb,
  error_message text
);

alter table public.scans disable row level security;

create index if not exists scans_id_idx on public.scans (id);
create index if not exists scans_status_idx on public.scans (status);
```

â†’ **Run** klicken, dann:

**Migration 002** â€“ `requester_ip`-Spalte fÃ¼r Idempotency:

```sql
-- Inhalt von: supabase/migrations/002_add_requester_ip.sql
alter table public.scans add column if not exists requester_ip text;

create index if not exists scans_ip_url_created_idx
  on public.scans (requester_ip, url, created_at desc);
```

â†’ **Run** klicken.

### API-SchlÃ¼ssel finden

**Settings â†’ API** im Supabase-Dashboard:

| Wert | Wo im Dashboard |
|---|---|
| `SUPABASE_URL` | â€Project URL" |
| `SUPABASE_SERVICE_ROLE_KEY` | â€service_role" (unter â€Project API keys") |

> âš ï¸ Den `anon`-Key **nicht** verwenden â€” nur den `service_role`-Key.

---

## ENV-Variablen

### `apps/web/.env.local`

| Variable | Pflicht | Beispiel | Beschreibung |
|---|---|---|---|
| `SUPABASE_URL` | âœ… | `https://abc.supabase.co` | Supabase Project URL |
| `SUPABASE_SERVICE_ROLE_KEY` | âœ… | `eyJh...` | Service-Role-SchlÃ¼ssel (niemals ins Frontend!) |
| `WORKER_URL` | âœ… | `http://localhost:3001` | Base-URL des Worker-Services |
| `ALLOW_DEV_PORTS` | â€” | `true` | Erlaubt Ports 8080/8443 beim URL-Scan (nur lokal) |

### `apps/worker/.env`

| Variable | Pflicht | Beispiel | Beschreibung |
|---|---|---|---|
| `SUPABASE_URL` | âœ… | `https://abc.supabase.co` | Supabase Project URL |
| `SUPABASE_SERVICE_ROLE_KEY` | âœ… | `eyJh...` | Service-Role-SchlÃ¼ssel |
| `PORT` | â€” | `3001` | Worker-Port (default: 3001) |

> âš ï¸ **Niemals** `SUPABASE_SERVICE_ROLE_KEY` mit dem PrÃ¤fix `NEXT_PUBLIC_` versehen.
> Er wÃ¼rde sonst im Browser-Bundle landen und Ã¶ffentlich sichtbar werden.

---

## Lokal ausfÃ¼hren

```bash
# Worker starten (Terminal 1)
pnpm dev:worker
# â†’ http://localhost:3001/health  {"status":"ok","service":"dsgvo-worker"}

# Web starten (Terminal 2)
pnpm dev:web
# â†’ http://localhost:3000  (Redirect zu /scan)
```

### Relevante URLs

| URL | Beschreibung |
|---|---|
| http://localhost:3000/scan | URL-Eingabe-Formular |
| http://localhost:3000/scan/`<uuid>` | Scan-Ergebnis mit Polling |
| http://localhost:3001/health | Worker Health-Check |

---

## Smoke Tests

```bash
# 1. Sauber â€” keine Tracker
pnpm --filter worker scan:demo https://example.com

# 2. Mit Trackern (Google Fonts, Analytics erkennbar)
pnpm --filter worker scan:demo https://nytimes.com

# 3. SSRF geblockt â€” lokale Adresse
pnpm --filter worker scan:demo http://localhost
pnpm --filter worker scan:demo http://127.0.0.1
pnpm --filter worker scan:demo http://192.168.1.1
```

### Rate Limit testen (API)

```bash
# 11 schnelle POST-Requests â†’ letzter sollte 429 zurÃ¼ckgeben
for i in {1..11}; do
  curl -s -o /dev/null -w "%{http_code}\n" \
    -X POST http://localhost:3000/api/scan \
    -H "Content-Type: application/json" \
    -d '{"url":"https://example.com"}'
done
```

---

## Troubleshooting

### Playwright: Browser nicht gefunden

```
Error: browserType.launch: Executable doesn't exist at ...
```

**Fix:**
```bash
pnpm --filter worker exec playwright install chromium
```

---

### `.env` wird nicht geladen (Windows)

Auf Windows erstellt der Explorer manchmal `.env.txt` statt `.env`.
Im Terminal prÃ¼fen:

```powershell
# PowerShell
Get-ChildItem -Force apps/worker/ | Where-Object Name -like "*.env*"
# Sollte ".env" zeigen, nicht ".env.txt"
```

Falls `.env.txt`: Datei umbenennen oder im Terminal anlegen:
```bash
cp apps/worker/.env.example apps/worker/.env
# Dann mit Editor Ã¶ffnen und Werte eintragen
```

---

### Scan bleibt auf "queued" stecken

Der Worker ist nicht erreichbar. PrÃ¼fen:

1. LÃ¤uft der Worker? â†’ `http://localhost:3001/health` im Browser aufrufen
2. Stimmt `WORKER_URL` in `apps/web/.env.local`? (kein Trailing-Slash!)
3. Worker-Terminal auf Fehler prÃ¼fen

---

### 429 Too Many Requests beim Testen

Rate Limit: **10 Scans pro 10 Minuten** + **10s Cooldown** pro IP.

Beim lokalen Testen: kurz warten oder eine andere URL verwenden.
Der `Retry-After`-Header gibt an, wie viele Sekunden zu warten sind.

---

### `blocked_url` â€” URL nicht erlaubt

Folgende URLs werden grundsÃ¤tzlich geblockt:

- `http://localhost`, `http://127.0.0.1`, `http://10.x.x.x` â†’ private/lokale Adressen
- `http://1.2.3.4` â†’ direkte IP-Adressen (alle geblockt)
- `http://user:pass@example.com` â†’ eingebettete Zugangsdaten
- Ports auÃŸer 80/443 (auÃŸer `ALLOW_DEV_PORTS=true` gesetzt)

---

### Supabase Fehler: `permission denied` oder `relation does not exist`

- PrÃ¼fen ob der `service_role`-Key (nicht `anon`!) in `.env` steht
- PrÃ¼fen ob beide Migrationen ausgefÃ¼hrt wurden (SQL Editor â†’ Table Editor â†’ `scans`-Tabelle sichtbar?)
- URL muss mit `https://` beginnen, kein Trailing-Slash

---

### Worker: `dns_failed` bei valider Domain

Das passiert wenn:
- Die Domain nicht existiert (Tipp-Fehler)
- DNS-Server lokal nicht erreichbar
- DNS-Timeout (5s) Ã¼berschritten (seltenes Netzwerkproblem)

**Fix:** URL nochmals prÃ¼fen. Bei korrekter Domain: kurz warten und erneut scannen.

---

## Security Notes

### Service Role Key

Der `SUPABASE_SERVICE_ROLE_KEY` umgeht Supabase Row Level Security (RLS).
RLS ist fÃ¼r den MVP bewusst deaktiviert (alle Zugriffe laufen server-seitig).

**Vor einem Ã¶ffentlichen Launch:**
1. RLS aktivieren: `ALTER TABLE scans ENABLE ROW LEVEL SECURITY;`
2. Policies definieren oder Service-Role-Zugriff auf dedizierte Backend-Funktion beschrÃ¤nken
3. Key niemals in Client-Code oder Git-History exponieren

### SSRF-Schutz (Server-Side Request Forgery)

Zwei Schutzschichten:

1. **Synchron (validateUrl):** Blockt private IPs, IP-Literals, Credentials, Non-Standard-Ports
2. **Asynchron (DNS-Rebind):** LÃ¶st den Hostnamen auf und prÃ¼ft alle returned IPs gegen private Ranges â€” verhindert, dass `evil.com â†’ 10.0.0.1` durchkommt

Beide Schichten laufen im Web (API Route) **und** im Worker (vor Playwright-Launch).

### Rate Limiting

In-Memory-Implementierung â€” funktioniert nur in Single-Process-Deployments.
FÃ¼r Vercel/Serverless: durch [Upstash Rate Limit](https://upstash.com/docs/redis/sdks/ratelimit/overview) ersetzen.

### Playwright Sandbox

Chromium lÃ¤uft mit `--no-sandbox` (Docker/CI-KompatibilitÃ¤t). In Produktionsumgebungen:
- Worker in einem Container mit minimalen Rechten ausfÃ¼hren
- Netzwerk-Egress auf erlaubte Ports/IPs einschrÃ¤nken (Firewall-Regeln)
- Ressourcen-Limits setzen (CPU/RAM pro Scan)

---

## Skripte (Ãœbersicht)

```bash
pnpm install               # Dependencies installieren
pnpm dev                   # Worker + Web parallel starten
pnpm dev:worker            # Nur Worker starten
pnpm dev:web               # Nur Web starten
pnpm build                 # Produktions-Build (Web + Worker)
pnpm typecheck             # TypeScript-Check (Worker + Web)
pnpm lint                  # ESLint (Web)

# Demo-Scan (kein Supabase nÃ¶tig)
pnpm --filter worker scan:demo https://example.com

# Playwright-Browser installieren
pnpm --filter worker exec playwright install chromium
```

---

## Was als NÃ¤chstes

### Monitoring

- **Fehlertracking:** [Sentry](https://sentry.io) in Worker + Web einbinden (5 Minuten Setup)
- **Uptime:** Worker `/health` mit [UptimeRobot](https://uptimerobot.com) Ã¼berwachen
- **Scan-Metriken:** `result.meta.scanDurationMs` in ein Dashboard schreiben (Grafana / Supabase Studio)

### Features

- **PDF-Report:** Scan-Ergebnis als druckbares PDF exportieren
- **Scheduled Scans:** TÃ¤gliche/wÃ¶chentliche Wiederholung per Cron + E-Mail-Diff
- **History:** Supabase Auth + RLS â†’ Nutzer sehen ihre vergangenen Scans
- **API-Zugang:** API-Key-System fÃ¼r Entwickler (programmatischer Scan-Aufruf)
- **Batch-Scan:** Mehrere URLs gleichzeitig (Queue mit [BullMQ](https://bullmq.io))

### Monetarisierung

- **Freemium:** 5 Scans/Tag kostenlos, dann Stripe-Abo fÃ¼r unbegrenzte Scans
- **Pay-per-Scan:** Prepaid Credits (Stripe Billing)
- **B2B-Whitelabel:** Agentur-Plan mit eigenem Branding + PDF-Reports
- **API-as-a-Service:** Volumenbasierte Abrechnung fÃ¼r Devs

---

## Lizenz

MIT â€” siehe [LICENSE](LICENSE) (noch anzulegen)
